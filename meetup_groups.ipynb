{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as time\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"data/meetups\"\n",
    "min_groupsize = 2\n",
    "max_groupsize = 500\n",
    "num_categories = 33\n",
    "group_blacklist = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = pd.read_csv(datadir+'/members.csv',delimiter = ',' , encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "membersSF = members[members.city == \"San Francisco\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1493407\n"
     ]
    }
   ],
   "source": [
    "print(len(membersSF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sizes = {}\n",
    "for index, row in membersSF.iterrows():\n",
    "    group_id = str(row[\"group_id\"])\n",
    "    if group_id in group_sizes:\n",
    "        group_sizes[group_id] += 1\n",
    "    else:\n",
    "        group_sizes[group_id] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in group_sizes:\n",
    "    if group_sizes[group]>max_groupsize or group_sizes[group]<min_groupsize:\n",
    "        group_blacklist.add(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.read_csv(datadir+'/groups.csv')\n",
    "grouplookup = {}\n",
    "for index, row in groups.iterrows():\n",
    "    if str(row[\"group_id\"]) not in group_blacklist:\n",
    "        m = str(row[\"category_id\"])\n",
    "        if m == \"36\":\n",
    "            m = \"19\"\n",
    "        if m == \"34\":\n",
    "            m = \"7\"\n",
    "        grouplookup[str(row[\"group_id\"])] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperedges = {}\n",
    "for index, row in membersSF.iterrows():\n",
    "    if str(row[\"group_id\"]) not in group_blacklist:\n",
    "        group_id = str(row[\"group_id\"])\n",
    "        if group_id in hyperedges:\n",
    "            hyperedges[group_id][\"members\"].append(str(row[\"member_id\"]))\n",
    "        else:\n",
    "            group = []\n",
    "            group.append(str(row[\"member_id\"]))\n",
    "            hyperedges[group_id] = {}\n",
    "            hyperedges[group_id][\"members\"] = group\n",
    "            hyperedges[group_id][\"category\"] = grouplookup[group_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexMemberships = {}\n",
    "for index, row in membersSF.iterrows():\n",
    "    if str(row[\"group_id\"]) not in group_blacklist:\n",
    "        member_id = str(row[\"member_id\"])\n",
    "        if member_id in vertexMemberships:\n",
    "            vertexMemberships[member_id].append(str(row[\"group_id\"]))\n",
    "        else:\n",
    "            memberGroupList = []\n",
    "            memberGroupList.append(str(row[\"group_id\"]))\n",
    "            vertexMemberships[member_id] = memberGroupList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hyperedges))\n",
    "print(len(vertexMemberships))\n",
    "with open(datadir+'/hyperedges.p', 'wb') as fp:\n",
    "    pickle.dump(hyperedges, fp)\n",
    "with open(datadir+'/vertexMemberships.p', 'wb') as fp:\n",
    "    pickle.dump(vertexMemberships, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_amounts = {}\n",
    "cat_names = {}\n",
    "cat_vals = []\n",
    "cat_csv = pd.read_csv(datadir+'/categories.csv')\n",
    "for index, row in cat_csv.iterrows():\n",
    "    cat_names[str(row[\"category_id\"])] = row[\"category_name\"]\n",
    "    \n",
    "print(cat_names)\n",
    "\n",
    "\n",
    "for h in hyperedges:\n",
    "    if cat_names[str(hyperedges[h][\"category\"])] not in cat_vals:\n",
    "        cat_vals.append(cat_names[str(hyperedges[h][\"category\"])])\n",
    "    if cat_names[str(hyperedges[h][\"category\"])] not in cat_amounts:\n",
    "        cat_amounts[cat_names[str(hyperedges[h][\"category\"])]]=1\n",
    "    else:\n",
    "        cat_amounts[cat_names[str(hyperedges[h][\"category\"])]]+=1\n",
    "\n",
    "pd_df = pd.DataFrame(list(cat_amounts.items()))\n",
    "pd_df.columns =[\"Dim\",\"Count\"]\n",
    "# sort df by Count column\n",
    "pd_df = pd_df.sort_values(['Count']).reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "# plot barh chart with index as x values\n",
    "ax = sns.barplot(pd_df.index, pd_df.Count)\n",
    "ax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "ax.set(xlabel=\"Dim\", ylabel='Count')\n",
    "# add proper Dim values as x labels\n",
    "ax.set_xticklabels(pd_df.Dim)\n",
    "for item in ax.get_xticklabels(): item.set_rotation(90)\n",
    "for i, v in enumerate(pd_df[\"Count\"].iteritems()):        \n",
    "    ax.text(i ,v[1], \"{:,}\".format(v[1]), color='m', va ='bottom', rotation=45)\n",
    "print(cat_vals)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_names = {}\n",
    "# cat_csv = pd.read_csv(datadir+'/categories.csv')\n",
    "# for index, row in cat_csv.iterrows():\n",
    "#     cat_names[str(row[\"category_id\"])] = row[\"category_name\"]\n",
    "# cat_vals = [cat_names[key] for key in cat_names]\n",
    "# print(cat_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for h_index in hyperedges:\n",
    "#     hyperedge = hyperedges[h_index]\n",
    "#     if hyperedge[\"category\"]==\"2\" or hyperedge[\"category\"]==\"34\":\n",
    "#         hyperedge[\"category\"] = \"0\"\n",
    "#     else:\n",
    "#         hyperedge[\"category\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HypergraphRandomWalks import SubsampleAndTraverse\n",
    "\n",
    "walksSAT = SubsampleAndTraverse(length=50, \n",
    "                                   num_walks=50, \n",
    "                                   hyperedges=hyperedges, \n",
    "                                   vertexMemberships=vertexMemberships,\n",
    "                                   p_traverse_method=\"inverse\",\n",
    "                                   p_traverse=0.15, \n",
    "                                   p_traverse_initial=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HypergraphRandomWalks import TraverseAndSelect\n",
    "\n",
    "walksTAS = TraverseAndSelect(length=50, \n",
    "                               num_walks=50, \n",
    "                               hyperedges=hyperedges, \n",
    "                               vertexMemberships=vertexMemberships,\n",
    "                               p_select_method=\"inverse\",\n",
    "                               p_select=0.15, \n",
    "                               p_select_initial=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datadir+'/walksSAT.p', 'wb') as fp:\n",
    "    pickle.dump(walksSAT, fp)\n",
    "\n",
    "with open(datadir+'/walksTAS.p', 'wb') as fp:\n",
    "    pickle.dump(walksTAS, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Embeddings import EmbedWord2Vec\n",
    "\n",
    "vertex_embedding_dimension = 16\n",
    "hyperedge_embedding_dimension = 128\n",
    "\n",
    "vertex_ids, vertex_embeddings = EmbedWord2Vec(walks=walksSAT,dimension=vertex_embedding_dimension)\n",
    "print(\"Vertex embeddings finished.\")\n",
    "hyperedge_ids, hyperedge_embeddings = EmbedWord2Vec(walks=walksTAS,dimension=hyperedge_embedding_dimension)\n",
    "print(\"Hyperedge embeddings finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vertex_embeddings))\n",
    "with open(datadir+'/vertex_embeddings_'+str(max_groupsize)+'.p', 'wb') as fp:\n",
    "    pickle.dump(vertex_embeddings, fp)\n",
    "print(len(hyperedge_embeddings))\n",
    "with open(datadir+'/hyperedge_embeddings_'+str(max_groupsize)+'.p', 'wb') as fp:\n",
    "    pickle.dump(hyperedge_embeddings, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(datadir+'/hyperedges.p', 'rb') as rb:\n",
    "#      hyperedges = pickle.load(rb)\n",
    "# with open(datadir+'/vertexMemberships.p', 'rb') as rb:\n",
    "#     vertexMemberships = pickle.load(rb)\n",
    "# with open(datadir+'/walks_hyperedge.p', 'rb') as rb:\n",
    "#     walks_hyperedge = pickle.load(rb)\n",
    "# with open(datadir+'/walk_labels_hyperedge.p', 'rb') as rb:\n",
    "#     walk_labels_hyperedge = pickle.load(rb)\n",
    "# with open(datadir+'/walks_node.p', 'rb') as rb:\n",
    "#     walks_node = pickle.load(rb)\n",
    "# with open (datadir+'/node_embeddings.p', 'rb') as rb:\n",
    "#     node_embeddings = pickle.load(rb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def visualizePCA(embeddings,obj,with_labels=None,ids=None):\n",
    "    transform = PCA\n",
    "\n",
    "    trans = transform(n_components=2)\n",
    "    embeddings_2d = trans.fit_transform(embeddings)\n",
    "\n",
    "    alpha = 0.7\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.axes().set(aspect=\"equal\")\n",
    "    \n",
    "    if with_labels:\n",
    "        targets = [int(with_labels[identifier]['category'])-1 for identifier in ids]\n",
    "        cmap = cm.rainbow(np.linspace(0.0, 1.0, num_categories))\n",
    "        colors = cmap[targets]\n",
    "        \n",
    "        plt.scatter(embeddings_2d[:,0], \n",
    "                    embeddings_2d[:,1], \n",
    "                    cmap=\"jet\", c=colors, alpha=alpha)\n",
    "    else:\n",
    "        plt.scatter(embeddings_2d[:,0], \n",
    "                    embeddings_2d[:,1], \n",
    "                    cmap=\"jet\", alpha=alpha)\n",
    "    \n",
    "    plt.title('PCA visualization of '+obj+' embeddings in the hypergraph.'.format(transform.__name__))\n",
    "    plt.show()\n",
    "    \n",
    "def visualizeTSNE(embeddings,obj,with_labels=None,ids=None):\n",
    "    transform = TSNE\n",
    "\n",
    "    trans = transform(n_components=2)\n",
    "    embeddings_2d = trans.fit_transform(embeddings)\n",
    "\n",
    "    alpha = 0.7\n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.axes().set(aspect=\"equal\")\n",
    "    \n",
    "    if with_labels:\n",
    "        targets = [int(with_labels[identifier]['category'])-1 for identifier in ids]\n",
    "        cmap = cm.rainbow(np.linspace(0.0, 1.0, num_categories))\n",
    "        colors = cmap[targets]\n",
    "        \n",
    "        plt.scatter(embeddings_2d[:,0], \n",
    "                    embeddings_2d[:,1], \n",
    "                    cmap=\"jet\", c=colors, alpha=alpha)\n",
    "    else:\n",
    "        plt.scatter(embeddings_2d[:,0], \n",
    "                    embeddings_2d[:,1], \n",
    "                    cmap=\"jet\", alpha=alpha)\n",
    "    \n",
    "    plt.title('TSNE visualization of '+obj+' embeddings in the hypergraph.'.format(transform.__name__))\n",
    "    plt.show()\n",
    "    \n",
    "visualizePCA(vertex_embeddings,\"vertex\")\n",
    "visualizeTSNE(hyperedge_embeddings,\"hyperedge\",hyperedges,hyperedge_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "(5983, 8128)\n",
      "(5983, 33)\n"
     ]
    }
   ],
   "source": [
    "def getTrainingData():\n",
    "    i = 0\n",
    "    lists = []\n",
    "    labels = []\n",
    "    maxi = 0\n",
    "    for h in hyperedges:\n",
    "        \n",
    "        vertex_embedding_list = []\n",
    "        hyperedge = hyperedges[h]\n",
    "        for vertex in hyperedge[\"members\"]:\n",
    "            i+=1\n",
    "            if i%100000==0:\n",
    "                print(i)\n",
    "            try: # Good ol' nondeterminism\n",
    "                vertex_embedding_list.append(vertex_embeddings[vertex_ids.index(vertex)].tolist())\n",
    "            except:\n",
    "                print(\"Missed one: \",vertex)\n",
    "        lists.append({\"v\":vertex_embedding_list,\"h\":hyperedge_embeddings[hyperedge_ids.index(h)].tolist()})\n",
    "        label = np.zeros((num_categories,))\n",
    "        label[int(hyperedge[\"category\"])-1] = 1\n",
    "        labels.append(label)\n",
    "    X_unshuffled = []\n",
    "    \n",
    "    for hlist in lists:\n",
    "        np_vertex_embeddings = np.asarray(hlist[\"v\"])\n",
    "        x = np.zeros((hyperedge_embedding_dimension + vertex_embedding_dimension*max_groupsize,))\n",
    "        i = 0\n",
    "        x[:hyperedge_embedding_dimension] = hlist[\"h\"]\n",
    "        \n",
    "        for embedding in np_vertex_embeddings:\n",
    "            x[hyperedge_embedding_dimension + i*embedding.shape[0]:hyperedge_embedding_dimension + (i+1)*embedding.shape[0]] = embedding\n",
    "            i+=1\n",
    "        X_unshuffled.append(x)\n",
    "    labels = np.asarray(labels)\n",
    "    X_arr, Y_arr = shuffle(X_unshuffled, labels)\n",
    "    X = np.asarray(X_arr)\n",
    "    Y = np.asarray(Y_arr)\n",
    "    return X, Y\n",
    "\n",
    "X, Y = getTrainingData()\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "# np.save(datadir+'/X_hyperedge_'+str(max_groupsize)+'.npy', X)\n",
    "# np.save(datadir+'/Y_hyperedge_'+str(max_groupsize)+'.npy', Y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.9, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Train on 4845 samples, validate on 539 samples\n",
      "Epoch 1/70\n",
      "4845/4845 [==============================] - 26s 5ms/step - loss: 2.7698 - mean_absolute_error: 0.0511 - categorical_accuracy: 0.3007 - f1_m: 0.1605 - val_loss: 2.3792 - val_mean_absolute_error: 0.0467 - val_categorical_accuracy: 0.3618 - val_f1_m: 0.3501\n",
      "Epoch 2/70\n",
      "4845/4845 [==============================] - 6s 1ms/step - loss: 2.1817 - mean_absolute_error: 0.0440 - categorical_accuracy: 0.4072 - f1_m: 0.3981 - val_loss: 2.1621 - val_mean_absolute_error: 0.0438 - val_categorical_accuracy: 0.4212 - val_f1_m: 0.4009\n",
      "Epoch 3/70\n",
      "4845/4845 [==============================] - 6s 1ms/step - loss: 2.0023 - mean_absolute_error: 0.0411 - categorical_accuracy: 0.4574 - f1_m: 0.4452 - val_loss: 2.0353 - val_mean_absolute_error: 0.0416 - val_categorical_accuracy: 0.4545 - val_f1_m: 0.4323\n",
      "Epoch 4/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.8927 - mean_absolute_error: 0.0395 - categorical_accuracy: 0.4923 - f1_m: 0.4780 - val_loss: 1.9608 - val_mean_absolute_error: 0.0406 - val_categorical_accuracy: 0.4712 - val_f1_m: 0.4396\n",
      "Epoch 5/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.8062 - mean_absolute_error: 0.0383 - categorical_accuracy: 0.5174 - f1_m: 0.4938 - val_loss: 1.8888 - val_mean_absolute_error: 0.0395 - val_categorical_accuracy: 0.4954 - val_f1_m: 0.4562\n",
      "Epoch 6/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.7342 - mean_absolute_error: 0.0374 - categorical_accuracy: 0.5375 - f1_m: 0.5094 - val_loss: 1.8367 - val_mean_absolute_error: 0.0390 - val_categorical_accuracy: 0.5046 - val_f1_m: 0.4585\n",
      "Epoch 7/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.6713 - mean_absolute_error: 0.0366 - categorical_accuracy: 0.5511 - f1_m: 0.5156 - val_loss: 1.7852 - val_mean_absolute_error: 0.0383 - val_categorical_accuracy: 0.5102 - val_f1_m: 0.4706\n",
      "Epoch 8/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.6138 - mean_absolute_error: 0.0359 - categorical_accuracy: 0.5682 - f1_m: 0.5228 - val_loss: 1.7428 - val_mean_absolute_error: 0.0377 - val_categorical_accuracy: 0.5250 - val_f1_m: 0.4717\n",
      "Epoch 9/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 1.5628 - mean_absolute_error: 0.0352 - categorical_accuracy: 0.5783 - f1_m: 0.5336 - val_loss: 1.7105 - val_mean_absolute_error: 0.0380 - val_categorical_accuracy: 0.5380 - val_f1_m: 0.4755\n",
      "Epoch 10/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.5139 - mean_absolute_error: 0.0347 - categorical_accuracy: 0.5907 - f1_m: 0.5422 - val_loss: 1.6773 - val_mean_absolute_error: 0.0372 - val_categorical_accuracy: 0.5455 - val_f1_m: 0.4881\n",
      "Epoch 11/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.4706 - mean_absolute_error: 0.0342 - categorical_accuracy: 0.6043 - f1_m: 0.5530 - val_loss: 1.6460 - val_mean_absolute_error: 0.0361 - val_categorical_accuracy: 0.5436 - val_f1_m: 0.4994\n",
      "Epoch 12/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.4274 - mean_absolute_error: 0.0335 - categorical_accuracy: 0.6151 - f1_m: 0.5650 - val_loss: 1.6162 - val_mean_absolute_error: 0.0357 - val_categorical_accuracy: 0.5584 - val_f1_m: 0.5098\n",
      "Epoch 13/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.3937 - mean_absolute_error: 0.0331 - categorical_accuracy: 0.6208 - f1_m: 0.5700 - val_loss: 1.5896 - val_mean_absolute_error: 0.0356 - val_categorical_accuracy: 0.5696 - val_f1_m: 0.5152\n",
      "Epoch 14/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.3579 - mean_absolute_error: 0.0326 - categorical_accuracy: 0.6256 - f1_m: 0.5735 - val_loss: 1.5776 - val_mean_absolute_error: 0.0358 - val_categorical_accuracy: 0.5733 - val_f1_m: 0.5219\n",
      "Epoch 15/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.3261 - mean_absolute_error: 0.0322 - categorical_accuracy: 0.6376 - f1_m: 0.5854 - val_loss: 1.5500 - val_mean_absolute_error: 0.0346 - val_categorical_accuracy: 0.5622 - val_f1_m: 0.5306\n",
      "Epoch 16/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.2930 - mean_absolute_error: 0.0317 - categorical_accuracy: 0.6425 - f1_m: 0.5935 - val_loss: 1.5394 - val_mean_absolute_error: 0.0345 - val_categorical_accuracy: 0.5714 - val_f1_m: 0.5356\n",
      "Epoch 17/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.2677 - mean_absolute_error: 0.0313 - categorical_accuracy: 0.6497 - f1_m: 0.6024 - val_loss: 1.5208 - val_mean_absolute_error: 0.0335 - val_categorical_accuracy: 0.5714 - val_f1_m: 0.5442\n",
      "Epoch 18/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.2458 - mean_absolute_error: 0.0309 - categorical_accuracy: 0.6553 - f1_m: 0.6068 - val_loss: 1.5119 - val_mean_absolute_error: 0.0340 - val_categorical_accuracy: 0.5918 - val_f1_m: 0.5612\n",
      "Epoch 19/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.2187 - mean_absolute_error: 0.0304 - categorical_accuracy: 0.6557 - f1_m: 0.6172 - val_loss: 1.4963 - val_mean_absolute_error: 0.0336 - val_categorical_accuracy: 0.5863 - val_f1_m: 0.5665\n",
      "Epoch 20/70\n",
      "4845/4845 [==============================] - 6s 1ms/step - loss: 1.1977 - mean_absolute_error: 0.0302 - categorical_accuracy: 0.6632 - f1_m: 0.6155 - val_loss: 1.4946 - val_mean_absolute_error: 0.0333 - val_categorical_accuracy: 0.5807 - val_f1_m: 0.5667\n",
      "Epoch 21/70\n",
      "4845/4845 [==============================] - 5s 1ms/step - loss: 1.1724 - mean_absolute_error: 0.0299 - categorical_accuracy: 0.6737 - f1_m: 0.6251 - val_loss: 1.4735 - val_mean_absolute_error: 0.0332 - val_categorical_accuracy: 0.5955 - val_f1_m: 0.5766\n",
      "Epoch 22/70\n",
      "4845/4845 [==============================] - 6s 1ms/step - loss: 1.1453 - mean_absolute_error: 0.0291 - categorical_accuracy: 0.6768 - f1_m: 0.6341 - val_loss: 1.4792 - val_mean_absolute_error: 0.0337 - val_categorical_accuracy: 0.5918 - val_f1_m: 0.5797\n",
      "Epoch 23/70\n",
      "4845/4845 [==============================] - 5s 1ms/step - loss: 1.1270 - mean_absolute_error: 0.0289 - categorical_accuracy: 0.6844 - f1_m: 0.6439 - val_loss: 1.4612 - val_mean_absolute_error: 0.0327 - val_categorical_accuracy: 0.6011 - val_f1_m: 0.5876\n",
      "Epoch 24/70\n",
      "4845/4845 [==============================] - 5s 1ms/step - loss: 1.1097 - mean_absolute_error: 0.0286 - categorical_accuracy: 0.6892 - f1_m: 0.6469 - val_loss: 1.4612 - val_mean_absolute_error: 0.0328 - val_categorical_accuracy: 0.5955 - val_f1_m: 0.5835\n",
      "Epoch 25/70\n",
      "4845/4845 [==============================] - 6s 1ms/step - loss: 1.0811 - mean_absolute_error: 0.0282 - categorical_accuracy: 0.6997 - f1_m: 0.6596 - val_loss: 1.4566 - val_mean_absolute_error: 0.0325 - val_categorical_accuracy: 0.5918 - val_f1_m: 0.5875\n",
      "Epoch 26/70\n",
      "4845/4845 [==============================] - 5s 1ms/step - loss: 1.0767 - mean_absolute_error: 0.0283 - categorical_accuracy: 0.6972 - f1_m: 0.6506 - val_loss: 1.4524 - val_mean_absolute_error: 0.0326 - val_categorical_accuracy: 0.5900 - val_f1_m: 0.5848\n",
      "Epoch 27/70\n",
      "4845/4845 [==============================] - 5s 1ms/step - loss: 1.0558 - mean_absolute_error: 0.0278 - categorical_accuracy: 0.6976 - f1_m: 0.6638 - val_loss: 1.4651 - val_mean_absolute_error: 0.0334 - val_categorical_accuracy: 0.5918 - val_f1_m: 0.5668\n",
      "Epoch 28/70\n",
      "4845/4845 [==============================] - 5s 1ms/step - loss: 1.0416 - mean_absolute_error: 0.0276 - categorical_accuracy: 0.7063 - f1_m: 0.6689 - val_loss: 1.4527 - val_mean_absolute_error: 0.0322 - val_categorical_accuracy: 0.5955 - val_f1_m: 0.5957\n",
      "Epoch 29/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.0262 - mean_absolute_error: 0.0272 - categorical_accuracy: 0.7096 - f1_m: 0.6747 - val_loss: 1.4649 - val_mean_absolute_error: 0.0324 - val_categorical_accuracy: 0.5881 - val_f1_m: 0.5750\n",
      "Epoch 30/70\n",
      "4845/4845 [==============================] - 8s 2ms/step - loss: 1.0050 - mean_absolute_error: 0.0267 - categorical_accuracy: 0.7129 - f1_m: 0.6834 - val_loss: 1.4486 - val_mean_absolute_error: 0.0315 - val_categorical_accuracy: 0.6011 - val_f1_m: 0.6032\n",
      "Epoch 31/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.9925 - mean_absolute_error: 0.0266 - categorical_accuracy: 0.7197 - f1_m: 0.6867 - val_loss: 1.4328 - val_mean_absolute_error: 0.0311 - val_categorical_accuracy: 0.6067 - val_f1_m: 0.6040\n",
      "Epoch 32/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.9688 - mean_absolute_error: 0.0260 - categorical_accuracy: 0.7249 - f1_m: 0.6959 - val_loss: 1.4458 - val_mean_absolute_error: 0.0316 - val_categorical_accuracy: 0.6122 - val_f1_m: 0.5886\n",
      "Epoch 33/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.9593 - mean_absolute_error: 0.0261 - categorical_accuracy: 0.7232 - f1_m: 0.6945 - val_loss: 1.4500 - val_mean_absolute_error: 0.0311 - val_categorical_accuracy: 0.6085 - val_f1_m: 0.5992\n",
      "Epoch 34/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.9503 - mean_absolute_error: 0.0259 - categorical_accuracy: 0.7282 - f1_m: 0.7004 - val_loss: 1.4400 - val_mean_absolute_error: 0.0316 - val_categorical_accuracy: 0.5993 - val_f1_m: 0.5877\n",
      "Epoch 35/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.9408 - mean_absolute_error: 0.0257 - categorical_accuracy: 0.7290 - f1_m: 0.7028 - val_loss: 1.4409 - val_mean_absolute_error: 0.0307 - val_categorical_accuracy: 0.6048 - val_f1_m: 0.5976\n",
      "Epoch 36/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.9214 - mean_absolute_error: 0.0253 - categorical_accuracy: 0.7335 - f1_m: 0.7094 - val_loss: 1.4555 - val_mean_absolute_error: 0.0310 - val_categorical_accuracy: 0.6085 - val_f1_m: 0.6049\n",
      "Epoch 37/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.9112 - mean_absolute_error: 0.0252 - categorical_accuracy: 0.7377 - f1_m: 0.7093 - val_loss: 1.4599 - val_mean_absolute_error: 0.0313 - val_categorical_accuracy: 0.6141 - val_f1_m: 0.6015\n",
      "Epoch 38/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.8886 - mean_absolute_error: 0.0244 - categorical_accuracy: 0.7420 - f1_m: 0.7203 - val_loss: 1.4554 - val_mean_absolute_error: 0.0301 - val_categorical_accuracy: 0.6085 - val_f1_m: 0.6052\n",
      "Epoch 39/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.8786 - mean_absolute_error: 0.0244 - categorical_accuracy: 0.7507 - f1_m: 0.7195 - val_loss: 1.4457 - val_mean_absolute_error: 0.0307 - val_categorical_accuracy: 0.6141 - val_f1_m: 0.6023\n",
      "Epoch 40/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.8664 - mean_absolute_error: 0.0242 - categorical_accuracy: 0.7515 - f1_m: 0.7243 - val_loss: 1.4690 - val_mean_absolute_error: 0.0313 - val_categorical_accuracy: 0.5937 - val_f1_m: 0.5912\n",
      "Epoch 41/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.8517 - mean_absolute_error: 0.0239 - categorical_accuracy: 0.7540 - f1_m: 0.7318 - val_loss: 1.4586 - val_mean_absolute_error: 0.0306 - val_categorical_accuracy: 0.6011 - val_f1_m: 0.5995\n",
      "Epoch 42/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.8346 - mean_absolute_error: 0.0233 - categorical_accuracy: 0.7614 - f1_m: 0.7338 - val_loss: 1.4846 - val_mean_absolute_error: 0.0311 - val_categorical_accuracy: 0.5844 - val_f1_m: 0.5890\n",
      "Epoch 43/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.8280 - mean_absolute_error: 0.0233 - categorical_accuracy: 0.7587 - f1_m: 0.7408 - val_loss: 1.4611 - val_mean_absolute_error: 0.0297 - val_categorical_accuracy: 0.6122 - val_f1_m: 0.6044\n",
      "Epoch 44/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.8035 - mean_absolute_error: 0.0227 - categorical_accuracy: 0.7707 - f1_m: 0.7485 - val_loss: 1.4582 - val_mean_absolute_error: 0.0303 - val_categorical_accuracy: 0.6085 - val_f1_m: 0.6011\n",
      "Epoch 45/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.7995 - mean_absolute_error: 0.0228 - categorical_accuracy: 0.7692 - f1_m: 0.7499 - val_loss: 1.4653 - val_mean_absolute_error: 0.0296 - val_categorical_accuracy: 0.6085 - val_f1_m: 0.6069\n",
      "Epoch 46/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.7819 - mean_absolute_error: 0.0223 - categorical_accuracy: 0.7730 - f1_m: 0.7517 - val_loss: 1.4717 - val_mean_absolute_error: 0.0302 - val_categorical_accuracy: 0.6160 - val_f1_m: 0.6058\n",
      "Epoch 47/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.7646 - mean_absolute_error: 0.0220 - categorical_accuracy: 0.7837 - f1_m: 0.7604 - val_loss: 1.4850 - val_mean_absolute_error: 0.0291 - val_categorical_accuracy: 0.6160 - val_f1_m: 0.6093\n",
      "Epoch 48/70\n",
      "4845/4845 [==============================] - 9s 2ms/step - loss: 0.7538 - mean_absolute_error: 0.0218 - categorical_accuracy: 0.7827 - f1_m: 0.7642 - val_loss: 1.4728 - val_mean_absolute_error: 0.0294 - val_categorical_accuracy: 0.6011 - val_f1_m: 0.6008\n",
      "Epoch 49/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.7436 - mean_absolute_error: 0.0217 - categorical_accuracy: 0.7808 - f1_m: 0.7664 - val_loss: 1.4809 - val_mean_absolute_error: 0.0299 - val_categorical_accuracy: 0.5937 - val_f1_m: 0.5892\n",
      "Epoch 50/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.7241 - mean_absolute_error: 0.0211 - categorical_accuracy: 0.7920 - f1_m: 0.7748 - val_loss: 1.5011 - val_mean_absolute_error: 0.0296 - val_categorical_accuracy: 0.6048 - val_f1_m: 0.6049\n",
      "Epoch 51/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.7170 - mean_absolute_error: 0.0209 - categorical_accuracy: 0.7924 - f1_m: 0.7725 - val_loss: 1.5207 - val_mean_absolute_error: 0.0296 - val_categorical_accuracy: 0.5937 - val_f1_m: 0.5922\n",
      "Epoch 52/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.7013 - mean_absolute_error: 0.0206 - categorical_accuracy: 0.7983 - f1_m: 0.7810 - val_loss: 1.4935 - val_mean_absolute_error: 0.0294 - val_categorical_accuracy: 0.5937 - val_f1_m: 0.5969\n",
      "Epoch 53/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.6770 - mean_absolute_error: 0.0200 - categorical_accuracy: 0.8064 - f1_m: 0.7921 - val_loss: 1.5196 - val_mean_absolute_error: 0.0294 - val_categorical_accuracy: 0.5955 - val_f1_m: 0.5925\n",
      "Epoch 54/70\n",
      "4845/4845 [==============================] - 11s 2ms/step - loss: 0.6544 - mean_absolute_error: 0.0194 - categorical_accuracy: 0.8122 - f1_m: 0.8014 - val_loss: 1.5180 - val_mean_absolute_error: 0.0294 - val_categorical_accuracy: 0.6030 - val_f1_m: 0.5951\n",
      "Epoch 55/70\n",
      "4845/4845 [==============================] - 11s 2ms/step - loss: 0.6550 - mean_absolute_error: 0.0196 - categorical_accuracy: 0.8128 - f1_m: 0.7990 - val_loss: 1.5036 - val_mean_absolute_error: 0.0293 - val_categorical_accuracy: 0.6030 - val_f1_m: 0.6043\n",
      "Epoch 56/70\n",
      "4845/4845 [==============================] - 11s 2ms/step - loss: 0.6461 - mean_absolute_error: 0.0194 - categorical_accuracy: 0.8194 - f1_m: 0.8030 - val_loss: 1.5354 - val_mean_absolute_error: 0.0291 - val_categorical_accuracy: 0.5937 - val_f1_m: 0.5846\n",
      "Epoch 57/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.6491 - mean_absolute_error: 0.0196 - categorical_accuracy: 0.8175 - f1_m: 0.7999 - val_loss: 1.5165 - val_mean_absolute_error: 0.0289 - val_categorical_accuracy: 0.6067 - val_f1_m: 0.5978\n",
      "Epoch 58/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.6267 - mean_absolute_error: 0.0188 - categorical_accuracy: 0.8270 - f1_m: 0.8111 - val_loss: 1.5676 - val_mean_absolute_error: 0.0287 - val_categorical_accuracy: 0.5993 - val_f1_m: 0.6075\n",
      "Epoch 59/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.5941 - mean_absolute_error: 0.0181 - categorical_accuracy: 0.8336 - f1_m: 0.8232 - val_loss: 1.5747 - val_mean_absolute_error: 0.0296 - val_categorical_accuracy: 0.5918 - val_f1_m: 0.5901\n",
      "Epoch 60/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.5952 - mean_absolute_error: 0.0182 - categorical_accuracy: 0.8316 - f1_m: 0.8186 - val_loss: 1.5553 - val_mean_absolute_error: 0.0286 - val_categorical_accuracy: 0.6085 - val_f1_m: 0.6013\n",
      "Epoch 61/70\n",
      "4845/4845 [==============================] - 11s 2ms/step - loss: 0.6028 - mean_absolute_error: 0.0187 - categorical_accuracy: 0.8332 - f1_m: 0.8181 - val_loss: 1.5499 - val_mean_absolute_error: 0.0295 - val_categorical_accuracy: 0.5918 - val_f1_m: 0.5987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/70\n",
      "4845/4845 [==============================] - 11s 2ms/step - loss: 0.5712 - mean_absolute_error: 0.0177 - categorical_accuracy: 0.8398 - f1_m: 0.8277 - val_loss: 1.5689 - val_mean_absolute_error: 0.0293 - val_categorical_accuracy: 0.5788 - val_f1_m: 0.5751\n",
      "Epoch 63/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.5792 - mean_absolute_error: 0.0181 - categorical_accuracy: 0.8380 - f1_m: 0.8240 - val_loss: 1.5796 - val_mean_absolute_error: 0.0294 - val_categorical_accuracy: 0.5714 - val_f1_m: 0.5920\n",
      "Epoch 64/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.5993 - mean_absolute_error: 0.0187 - categorical_accuracy: 0.8312 - f1_m: 0.8180 - val_loss: 1.5561 - val_mean_absolute_error: 0.0287 - val_categorical_accuracy: 0.5918 - val_f1_m: 0.6020\n",
      "Epoch 65/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.5593 - mean_absolute_error: 0.0175 - categorical_accuracy: 0.8469 - f1_m: 0.8355 - val_loss: 1.5823 - val_mean_absolute_error: 0.0298 - val_categorical_accuracy: 0.5937 - val_f1_m: 0.5931\n",
      "Epoch 66/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.5317 - mean_absolute_error: 0.0168 - categorical_accuracy: 0.8512 - f1_m: 0.8432 - val_loss: 1.6034 - val_mean_absolute_error: 0.0283 - val_categorical_accuracy: 0.6085 - val_f1_m: 0.6048\n",
      "Epoch 67/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.5378 - mean_absolute_error: 0.0171 - categorical_accuracy: 0.8502 - f1_m: 0.8386 - val_loss: 1.6098 - val_mean_absolute_error: 0.0286 - val_categorical_accuracy: 0.5863 - val_f1_m: 0.5981\n",
      "Epoch 68/70\n",
      "4845/4845 [==============================] - 11s 2ms/step - loss: 0.5076 - mean_absolute_error: 0.0162 - categorical_accuracy: 0.8594 - f1_m: 0.8474 - val_loss: 1.6330 - val_mean_absolute_error: 0.0284 - val_categorical_accuracy: 0.5918 - val_f1_m: 0.6008\n",
      "Epoch 69/70\n",
      "4845/4845 [==============================] - 11s 2ms/step - loss: 0.4933 - mean_absolute_error: 0.0159 - categorical_accuracy: 0.8654 - f1_m: 0.8567 - val_loss: 1.6016 - val_mean_absolute_error: 0.0293 - val_categorical_accuracy: 0.5696 - val_f1_m: 0.5810\n",
      "Epoch 70/70\n",
      "4845/4845 [==============================] - 10s 2ms/step - loss: 0.4875 - mean_absolute_error: 0.0156 - categorical_accuracy: 0.8716 - f1_m: 0.8574 - val_loss: 1.6873 - val_mean_absolute_error: 0.0301 - val_categorical_accuracy: 0.5659 - val_f1_m: 0.5823\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from Models import DeepHyperedges\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "dataset_name = \"meetup\"\n",
    "batch_size = 128\n",
    "num_epochs = 70\n",
    "\n",
    "deephyperedges_model = DeepHyperedges(vertex_embedding_dimension=vertex_embedding_dimension,\n",
    "                                     hyperedge_embedding_dimension=hyperedge_embedding_dimension,\n",
    "                                     max_hyperedge_size=max_groupsize,\n",
    "                                     num_outputs=num_categories,\n",
    "                                     dataset_name=dataset_name)\n",
    "plot_model(deephyperedges_model, to_file='images/'+dataset_name+'_deephyperedges_model.png')\n",
    "checkpointer = ModelCheckpoint(filepath='weights/'+dataset_name+'/deephyperedges_weights.hdf5', verbose=0, save_best_only=True)\n",
    "tbCallBack = TensorBoard(log_dir='logs/'+dataset_name+'/deephyperedges_logs_multi', histogram_freq=0, batch_size=batch_size, write_graph=True, write_grads=True, write_images=True, update_freq='batch')\n",
    "\n",
    "history = deephyperedges_model.fit(X_train, Y_train, epochs=num_epochs, batch_size=batch_size,\n",
    "        shuffle=True, validation_split=0.1,\n",
    "        callbacks=[checkpointer,tbCallBack], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tech', 'Career & Business', 'Socializing', 'Games', 'Community & Environment', 'Sci-Fi & Fantasy', 'Health & Wellbeing', 'Singles', 'Education & Learning', 'Photography', 'Book Clubs', 'Religion & Beliefs', 'Movies & Film', 'Hobbies & Crafts', 'LGBT', 'Pets & Animals', 'Writing', 'New Age & Spirituality', 'Dancing', 'Food & Drink', 'Sports & Recreation', 'Arts & Culture', 'Music', 'Language & Ethnic Identity', 'Movements & Politics', 'Fashion & Beauty', 'Parents & Family', 'Outdoors & Adventure', 'Cars & Motorcycles', 'Fitness', 'Support', 'Lifestyle', 'Paranormal']\n",
      "599/599 [==============================] - 53s 89ms/step\n",
      "[30, 11, 13, 6, 1, 31, 26, 6, 22, 15, 9, 30, 6, 6, 20, 6, 13, 8, 20, 3, 6, 6, 6, 22, 6, 6, 8, 26, 13, 1, 9, 3, 13, 0, 6, 1, 1, 6, 31, 6, 22, 1, 6, 11, 1, 25, 30, 6, 29, 30, 30, 1, 6, 5, 13, 21, 6, 22, 26, 1, 10, 21, 6, 3, 6, 1, 6, 1, 30, 15, 12, 6, 5, 4, 1, 13, 0, 26, 1, 1, 30, 1, 0, 11, 1, 9, 1, 6, 3, 6, 3, 6, 19, 24, 9, 1, 29, 6, 6, 12, 6, 3, 30, 6, 6, 6, 6, 30, 5, 1, 13, 30, 3, 6, 21, 6, 30, 6, 15, 6, 30, 6, 22, 20, 13, 1, 30, 13, 6, 22, 9, 20, 22, 5, 6, 27, 6, 6, 10, 6, 15, 6, 4, 9, 1, 4, 6, 6, 9, 21, 13, 19, 6, 32, 1, 21, 6, 31, 6, 6, 15, 1, 6, 26, 13, 6, 6, 11, 18, 1, 1, 6, 6, 13, 6, 1, 6, 6, 13, 1, 1, 3, 21, 21, 6, 20, 1, 1, 5, 6, 15, 6, 1, 21, 4, 15, 1, 6, 6, 1, 6, 6, 31, 5, 1, 21, 1, 6, 6, 15, 6, 30, 6, 3, 13, 1, 0, 6, 6, 6, 13, 26, 6, 10, 11, 6, 8, 6, 1, 6, 1, 21, 6, 15, 13, 1, 1, 1, 21, 6, 15, 13, 1, 12, 15, 6, 1, 30, 15, 13, 1, 9, 6, 29, 6, 30, 29, 6, 6, 6, 6, 30, 24, 0, 1, 1, 12, 6, 1, 1, 1, 6, 1, 6, 22, 30, 6, 6, 21, 6, 1, 6, 0, 22, 1, 30, 1, 12, 30, 22, 6, 6, 6, 6, 30, 31, 30, 6, 22, 8, 13, 1, 30, 31, 6, 6, 6, 22, 4, 6, 6, 21, 5, 6, 1, 9, 9, 1, 9, 13, 6, 13, 19, 6, 6, 1, 0, 15, 20, 6, 6, 30, 6, 6, 15, 0, 15, 21, 6, 6, 5, 6, 29, 6, 6, 5, 6, 1, 6, 13, 15, 11, 10, 6, 9, 31, 30, 4, 13, 6, 6, 29, 1, 13, 22, 6, 21, 6, 10, 6, 15, 6, 5, 6, 6, 6, 6, 6, 0, 1, 6, 10, 1, 1, 6, 30, 13, 1, 1, 6, 6, 13, 8, 1, 6, 6, 30, 1, 6, 5, 6, 6, 6, 6, 15, 6, 30, 6, 30, 6, 13, 1, 21, 26, 0, 15, 6, 8, 1, 1, 13, 6, 30, 1, 3, 1, 1, 0, 1, 6, 17, 6, 30, 13, 6, 6, 3, 9, 32, 6, 15, 10, 1, 6, 30, 6, 3, 6, 6, 15, 6, 6, 10, 15, 3, 3, 13, 1, 21, 6, 31, 29, 13, 5, 20, 19, 8, 15, 9, 30, 6, 7, 6, 20, 9, 30, 3, 1, 1, 6, 5, 30, 29, 29, 6, 31, 11, 1, 6, 1, 14, 30, 13, 9, 6, 1, 20, 6, 3, 30, 20, 3, 0, 26, 6, 1, 26, 27, 6, 6, 6, 31, 1, 9, 21, 6, 12, 0, 6, 12, 31, 6, 6, 8, 13, 30, 5, 3, 31, 21, 15, 6, 1, 13, 21, 30, 0, 31, 19, 30, 1, 21, 30, 6, 1, 6, 13, 13, 1, 6, 6, 6, 24, 19, 1, 1, 6, 20, 6, 1, 6, 25, 27, 13, 6, 6, 31, 9, 1, 1, 11, 30, 6, 1, 12, 5, 11, 6, 6, 26, 1, 30, 7, 6, 31, 21, 1, 31, 1, 30, 31, 30, 15, 1, 19, 6, 18, 1, 22]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                      Tech       0.43      0.46      0.44        13\n",
      "         Career & Business       0.51      0.58      0.54        84\n",
      "               Socializing       0.00      0.00      0.00         2\n",
      "                     Games       0.39      0.47      0.42        15\n",
      "   Community & Environment       0.50      0.27      0.35        11\n",
      "          Sci-Fi & Fantasy       0.40      0.50      0.44        12\n",
      "        Health & Wellbeing       0.91      0.79      0.85       215\n",
      "                   Singles       1.00      0.40      0.57         5\n",
      "      Education & Learning       0.62      0.62      0.62         8\n",
      "               Photography       0.39      0.37      0.38        19\n",
      "                Book Clubs       0.38      0.38      0.38         8\n",
      "        Religion & Beliefs       0.67      1.00      0.80         6\n",
      "             Movies & Film       0.38      0.30      0.33        10\n",
      "          Hobbies & Crafts       0.32      0.50      0.39        24\n",
      "                      LGBT       1.00      0.17      0.29         6\n",
      "            Pets & Animals       0.32      0.53      0.40        15\n",
      "                   Writing       0.00      0.00      0.00         1\n",
      "    New Age & Spirituality       0.00      0.00      0.00         5\n",
      "                   Dancing       0.00      0.00      0.00         0\n",
      "              Food & Drink       0.14      0.25      0.18         4\n",
      "       Sports & Recreation       0.45      0.38      0.42        13\n",
      "            Arts & Culture       0.45      0.50      0.48        20\n",
      "                     Music       0.64      0.50      0.56        18\n",
      "Language & Ethnic Identity       0.00      0.00      0.00         1\n",
      "      Movements & Politics       0.67      0.67      0.67         3\n",
      "          Fashion & Beauty       0.00      0.00      0.00         3\n",
      "          Parents & Family       0.60      0.67      0.63         9\n",
      "      Outdoors & Adventure       0.33      0.17      0.22         6\n",
      "        Cars & Motorcycles       0.00      0.00      0.00         3\n",
      "                   Fitness       0.33      0.38      0.35         8\n",
      "                   Support       0.27      0.36      0.31        33\n",
      "                 Lifestyle       0.41      0.64      0.50        11\n",
      "                Paranormal       0.00      0.00      0.00         8\n",
      "\n",
      "                 micro avg       0.57      0.57      0.57       599\n",
      "                 macro avg       0.38      0.36      0.35       599\n",
      "              weighted avg       0.60      0.57      0.58       599\n",
      "\n",
      "0.5742904841402338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "target_names = cat_vals\n",
    "print(target_names)\n",
    "y_pred = deephyperedges_model.predict(X_test, batch_size=16, verbose=1)\n",
    "finals_pred = []\n",
    "finals_test = []\n",
    "for p in y_pred:\n",
    "    m = 0\n",
    "    ind = 0\n",
    "    final = 0\n",
    "    for i in p:\n",
    "        if i>m:\n",
    "            m=i\n",
    "            final=ind\n",
    "        ind+=1\n",
    "    finals_pred.append(final)\n",
    "\n",
    "for i in Y_test:\n",
    "    ind=0\n",
    "    for j in i:\n",
    "        if j==1:\n",
    "            finals_test.append(ind)\n",
    "        ind+=1\n",
    "           \n",
    "print(classification_report(finals_test, finals_pred, target_names=target_names))\n",
    "print(accuracy_score(finals_test, finals_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMLPTrainingData():\n",
    "    i = 0\n",
    "    lists = []\n",
    "    labels = []\n",
    "    maxi = 0\n",
    "    for h in hyperedges:\n",
    "        vertex_embedding_list = []\n",
    "        hyperedge = hyperedges[h]\n",
    "        lists.append({\"h\":hyperedge_embeddings[hyperedge_ids.index(h)].tolist()})\n",
    "        label = np.zeros((num_categories,))\n",
    "        label[int(hyperedge[\"category\"])-1] = 1\n",
    "        labels.append(label)\n",
    "    X_unshuffled = []\n",
    "    for hlist in lists:\n",
    "        x = np.zeros((hyperedge_embedding_dimension,))\n",
    "        x[:hyperedge_embedding_dimension] = hlist[\"h\"]\n",
    "        X_unshuffled.append(x)\n",
    "    labels = np.asarray(labels)\n",
    "    X_arr, Y_arr = shuffle(X_unshuffled, labels)\n",
    "    X_MLP = np.asarray(X_arr)\n",
    "    Y_MLP = np.asarray(Y_arr)\n",
    "    return X_MLP, Y_MLP\n",
    "\n",
    "X_MLP, Y_MLP = getMLPTrainingData()\n",
    "# np.save(datadir+'/X_MLP_'+str(max_groupsize)+'.npy', X_MLP)\n",
    "# np.save(datadir+'/Y_MLP_'+str(max_groupsize)+'.npy', Y_MLP)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_MLP_train, X_MLP_test, Y_MLP_train, Y_MLP_test = train_test_split(X_MLP, Y_MLP, train_size=0.9, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4845 samples, validate on 539 samples\n",
      "Epoch 1/50\n",
      "4845/4845 [==============================] - 6s 1ms/step - loss: 2.8413 - mean_absolute_error: 0.0526 - categorical_accuracy: 0.2918 - f1_m: 0.1156 - val_loss: 2.5075 - val_mean_absolute_error: 0.0486 - val_categorical_accuracy: 0.3748 - val_f1_m: 0.2165\n",
      "Epoch 2/50\n",
      "4845/4845 [==============================] - 1s 170us/step - loss: 2.2969 - mean_absolute_error: 0.0460 - categorical_accuracy: 0.3971 - f1_m: 0.3164 - val_loss: 2.2853 - val_mean_absolute_error: 0.0453 - val_categorical_accuracy: 0.4007 - val_f1_m: 0.3480\n",
      "Epoch 3/50\n",
      "4845/4845 [==============================] - 1s 169us/step - loss: 2.0957 - mean_absolute_error: 0.0429 - categorical_accuracy: 0.4438 - f1_m: 0.4018 - val_loss: 2.1589 - val_mean_absolute_error: 0.0429 - val_categorical_accuracy: 0.4230 - val_f1_m: 0.3954\n",
      "Epoch 4/50\n",
      "4845/4845 [==============================] - 1s 169us/step - loss: 1.9661 - mean_absolute_error: 0.0410 - categorical_accuracy: 0.4838 - f1_m: 0.4448 - val_loss: 2.0767 - val_mean_absolute_error: 0.0417 - val_categorical_accuracy: 0.4508 - val_f1_m: 0.4270\n",
      "Epoch 5/50\n",
      "4845/4845 [==============================] - 1s 176us/step - loss: 1.8694 - mean_absolute_error: 0.0395 - categorical_accuracy: 0.5100 - f1_m: 0.4732 - val_loss: 2.0111 - val_mean_absolute_error: 0.0406 - val_categorical_accuracy: 0.4750 - val_f1_m: 0.4508\n",
      "Epoch 6/50\n",
      "4845/4845 [==============================] - 1s 176us/step - loss: 1.7897 - mean_absolute_error: 0.0385 - categorical_accuracy: 0.5294 - f1_m: 0.4865 - val_loss: 1.9597 - val_mean_absolute_error: 0.0392 - val_categorical_accuracy: 0.4898 - val_f1_m: 0.4685\n",
      "Epoch 7/50\n",
      "4845/4845 [==============================] - 1s 178us/step - loss: 1.7218 - mean_absolute_error: 0.0374 - categorical_accuracy: 0.5496 - f1_m: 0.4985 - val_loss: 1.9130 - val_mean_absolute_error: 0.0389 - val_categorical_accuracy: 0.4954 - val_f1_m: 0.4737\n",
      "Epoch 8/50\n",
      "4845/4845 [==============================] - 1s 178us/step - loss: 1.6605 - mean_absolute_error: 0.0367 - categorical_accuracy: 0.5622 - f1_m: 0.5091 - val_loss: 1.8751 - val_mean_absolute_error: 0.0385 - val_categorical_accuracy: 0.5028 - val_f1_m: 0.4708\n",
      "Epoch 9/50\n",
      "4845/4845 [==============================] - 1s 173us/step - loss: 1.6048 - mean_absolute_error: 0.0360 - categorical_accuracy: 0.5746 - f1_m: 0.5193 - val_loss: 1.8427 - val_mean_absolute_error: 0.0382 - val_categorical_accuracy: 0.5139 - val_f1_m: 0.4760\n",
      "Epoch 10/50\n",
      "4845/4845 [==============================] - 1s 176us/step - loss: 1.5555 - mean_absolute_error: 0.0353 - categorical_accuracy: 0.5895 - f1_m: 0.5286 - val_loss: 1.8127 - val_mean_absolute_error: 0.0378 - val_categorical_accuracy: 0.5121 - val_f1_m: 0.4824\n",
      "Epoch 11/50\n",
      "4845/4845 [==============================] - 1s 173us/step - loss: 1.5109 - mean_absolute_error: 0.0348 - categorical_accuracy: 0.6039 - f1_m: 0.5367 - val_loss: 1.7873 - val_mean_absolute_error: 0.0373 - val_categorical_accuracy: 0.5269 - val_f1_m: 0.4852\n",
      "Epoch 12/50\n",
      "4845/4845 [==============================] - 1s 176us/step - loss: 1.4695 - mean_absolute_error: 0.0342 - categorical_accuracy: 0.6118 - f1_m: 0.5505 - val_loss: 1.7668 - val_mean_absolute_error: 0.0372 - val_categorical_accuracy: 0.5417 - val_f1_m: 0.4918\n",
      "Epoch 13/50\n",
      "4845/4845 [==============================] - 1s 174us/step - loss: 1.4326 - mean_absolute_error: 0.0337 - categorical_accuracy: 0.6215 - f1_m: 0.5569 - val_loss: 1.7481 - val_mean_absolute_error: 0.0366 - val_categorical_accuracy: 0.5417 - val_f1_m: 0.4999\n",
      "Epoch 14/50\n",
      "4845/4845 [==============================] - 1s 184us/step - loss: 1.3975 - mean_absolute_error: 0.0333 - categorical_accuracy: 0.6316 - f1_m: 0.5654 - val_loss: 1.7271 - val_mean_absolute_error: 0.0362 - val_categorical_accuracy: 0.5455 - val_f1_m: 0.5010\n",
      "Epoch 15/50\n",
      "4845/4845 [==============================] - 1s 191us/step - loss: 1.3655 - mean_absolute_error: 0.0327 - categorical_accuracy: 0.6369 - f1_m: 0.5744 - val_loss: 1.7110 - val_mean_absolute_error: 0.0360 - val_categorical_accuracy: 0.5455 - val_f1_m: 0.5072\n",
      "Epoch 16/50\n",
      "4845/4845 [==============================] - 1s 177us/step - loss: 1.3367 - mean_absolute_error: 0.0323 - categorical_accuracy: 0.6433 - f1_m: 0.5815 - val_loss: 1.7007 - val_mean_absolute_error: 0.0356 - val_categorical_accuracy: 0.5473 - val_f1_m: 0.5076\n",
      "Epoch 17/50\n",
      "4845/4845 [==============================] - 1s 176us/step - loss: 1.3094 - mean_absolute_error: 0.0319 - categorical_accuracy: 0.6481 - f1_m: 0.5903 - val_loss: 1.6801 - val_mean_absolute_error: 0.0357 - val_categorical_accuracy: 0.5510 - val_f1_m: 0.5046\n",
      "Epoch 18/50\n",
      "4845/4845 [==============================] - 1s 174us/step - loss: 1.2846 - mean_absolute_error: 0.0316 - categorical_accuracy: 0.6570 - f1_m: 0.5932 - val_loss: 1.6773 - val_mean_absolute_error: 0.0357 - val_categorical_accuracy: 0.5547 - val_f1_m: 0.5029\n",
      "Epoch 19/50\n",
      "4845/4845 [==============================] - 1s 172us/step - loss: 1.2608 - mean_absolute_error: 0.0312 - categorical_accuracy: 0.6599 - f1_m: 0.5987 - val_loss: 1.6608 - val_mean_absolute_error: 0.0354 - val_categorical_accuracy: 0.5510 - val_f1_m: 0.5065\n",
      "Epoch 20/50\n",
      "4845/4845 [==============================] - 1s 171us/step - loss: 1.2382 - mean_absolute_error: 0.0307 - categorical_accuracy: 0.6683 - f1_m: 0.6095 - val_loss: 1.6467 - val_mean_absolute_error: 0.0353 - val_categorical_accuracy: 0.5566 - val_f1_m: 0.5118\n",
      "Epoch 21/50\n",
      "4845/4845 [==============================] - 1s 166us/step - loss: 1.2165 - mean_absolute_error: 0.0305 - categorical_accuracy: 0.6714 - f1_m: 0.6131 - val_loss: 1.6483 - val_mean_absolute_error: 0.0353 - val_categorical_accuracy: 0.5510 - val_f1_m: 0.5020\n",
      "Epoch 22/50\n",
      "4845/4845 [==============================] - 1s 170us/step - loss: 1.1993 - mean_absolute_error: 0.0302 - categorical_accuracy: 0.6753 - f1_m: 0.6168 - val_loss: 1.6399 - val_mean_absolute_error: 0.0351 - val_categorical_accuracy: 0.5417 - val_f1_m: 0.5049\n",
      "Epoch 23/50\n",
      "4845/4845 [==============================] - 1s 166us/step - loss: 1.1790 - mean_absolute_error: 0.0299 - categorical_accuracy: 0.6784 - f1_m: 0.6231 - val_loss: 1.6331 - val_mean_absolute_error: 0.0346 - val_categorical_accuracy: 0.5473 - val_f1_m: 0.5159\n",
      "Epoch 24/50\n",
      "4845/4845 [==============================] - 1s 168us/step - loss: 1.1613 - mean_absolute_error: 0.0296 - categorical_accuracy: 0.6840 - f1_m: 0.6295 - val_loss: 1.6239 - val_mean_absolute_error: 0.0346 - val_categorical_accuracy: 0.5473 - val_f1_m: 0.5057\n",
      "Epoch 25/50\n",
      "4845/4845 [==============================] - 1s 174us/step - loss: 1.1453 - mean_absolute_error: 0.0293 - categorical_accuracy: 0.6904 - f1_m: 0.6337 - val_loss: 1.6199 - val_mean_absolute_error: 0.0343 - val_categorical_accuracy: 0.5492 - val_f1_m: 0.5157\n",
      "Epoch 26/50\n",
      "4845/4845 [==============================] - 1s 174us/step - loss: 1.1282 - mean_absolute_error: 0.0290 - categorical_accuracy: 0.6927 - f1_m: 0.6403 - val_loss: 1.6119 - val_mean_absolute_error: 0.0343 - val_categorical_accuracy: 0.5566 - val_f1_m: 0.5157\n",
      "Epoch 27/50\n",
      "4845/4845 [==============================] - 1s 172us/step - loss: 1.1149 - mean_absolute_error: 0.0289 - categorical_accuracy: 0.6958 - f1_m: 0.6447 - val_loss: 1.6111 - val_mean_absolute_error: 0.0340 - val_categorical_accuracy: 0.5566 - val_f1_m: 0.5240\n",
      "Epoch 28/50\n",
      "4845/4845 [==============================] - 1s 168us/step - loss: 1.1001 - mean_absolute_error: 0.0286 - categorical_accuracy: 0.6968 - f1_m: 0.6502 - val_loss: 1.6055 - val_mean_absolute_error: 0.0343 - val_categorical_accuracy: 0.5566 - val_f1_m: 0.5179\n",
      "Epoch 29/50\n",
      "4845/4845 [==============================] - 1s 169us/step - loss: 1.0873 - mean_absolute_error: 0.0283 - categorical_accuracy: 0.7005 - f1_m: 0.6554 - val_loss: 1.6092 - val_mean_absolute_error: 0.0339 - val_categorical_accuracy: 0.5529 - val_f1_m: 0.5249\n",
      "Epoch 30/50\n",
      "4845/4845 [==============================] - 1s 166us/step - loss: 1.0723 - mean_absolute_error: 0.0281 - categorical_accuracy: 0.7077 - f1_m: 0.6587 - val_loss: 1.6041 - val_mean_absolute_error: 0.0337 - val_categorical_accuracy: 0.5584 - val_f1_m: 0.5263\n",
      "Epoch 31/50\n",
      "4845/4845 [==============================] - 1s 168us/step - loss: 1.0572 - mean_absolute_error: 0.0278 - categorical_accuracy: 0.7084 - f1_m: 0.6653 - val_loss: 1.6076 - val_mean_absolute_error: 0.0336 - val_categorical_accuracy: 0.5622 - val_f1_m: 0.5284\n",
      "Epoch 32/50\n",
      "4845/4845 [==============================] - 1s 168us/step - loss: 1.0470 - mean_absolute_error: 0.0276 - categorical_accuracy: 0.7112 - f1_m: 0.6677 - val_loss: 1.5998 - val_mean_absolute_error: 0.0335 - val_categorical_accuracy: 0.5603 - val_f1_m: 0.5233\n",
      "Epoch 33/50\n",
      "4845/4845 [==============================] - 1s 169us/step - loss: 1.0353 - mean_absolute_error: 0.0275 - categorical_accuracy: 0.7150 - f1_m: 0.6726 - val_loss: 1.5959 - val_mean_absolute_error: 0.0334 - val_categorical_accuracy: 0.5733 - val_f1_m: 0.5327\n",
      "Epoch 34/50\n",
      "4845/4845 [==============================] - 1s 168us/step - loss: 1.0218 - mean_absolute_error: 0.0273 - categorical_accuracy: 0.7150 - f1_m: 0.6737 - val_loss: 1.6000 - val_mean_absolute_error: 0.0331 - val_categorical_accuracy: 0.5677 - val_f1_m: 0.5350\n",
      "Epoch 35/50\n",
      "4845/4845 [==============================] - 1s 170us/step - loss: 1.0107 - mean_absolute_error: 0.0270 - categorical_accuracy: 0.7185 - f1_m: 0.6796 - val_loss: 1.5962 - val_mean_absolute_error: 0.0334 - val_categorical_accuracy: 0.5622 - val_f1_m: 0.5290\n",
      "Epoch 36/50\n",
      "4845/4845 [==============================] - 1s 170us/step - loss: 0.9986 - mean_absolute_error: 0.0268 - categorical_accuracy: 0.7197 - f1_m: 0.6857 - val_loss: 1.6005 - val_mean_absolute_error: 0.0334 - val_categorical_accuracy: 0.5622 - val_f1_m: 0.5291\n",
      "Epoch 37/50\n",
      "4845/4845 [==============================] - 1s 173us/step - loss: 0.9875 - mean_absolute_error: 0.0267 - categorical_accuracy: 0.7220 - f1_m: 0.6858 - val_loss: 1.6021 - val_mean_absolute_error: 0.0332 - val_categorical_accuracy: 0.5696 - val_f1_m: 0.5347\n",
      "Epoch 38/50\n",
      "4845/4845 [==============================] - 1s 164us/step - loss: 0.9779 - mean_absolute_error: 0.0264 - categorical_accuracy: 0.7238 - f1_m: 0.6915 - val_loss: 1.5973 - val_mean_absolute_error: 0.0332 - val_categorical_accuracy: 0.5696 - val_f1_m: 0.5328\n",
      "Epoch 39/50\n",
      "4845/4845 [==============================] - 1s 174us/step - loss: 0.9668 - mean_absolute_error: 0.0262 - categorical_accuracy: 0.7259 - f1_m: 0.6947 - val_loss: 1.5987 - val_mean_absolute_error: 0.0330 - val_categorical_accuracy: 0.5714 - val_f1_m: 0.5403\n",
      "Epoch 40/50\n",
      "4845/4845 [==============================] - 1s 171us/step - loss: 0.9556 - mean_absolute_error: 0.0260 - categorical_accuracy: 0.7255 - f1_m: 0.6976 - val_loss: 1.5922 - val_mean_absolute_error: 0.0331 - val_categorical_accuracy: 0.5714 - val_f1_m: 0.5415\n",
      "Epoch 41/50\n",
      "4845/4845 [==============================] - 1s 173us/step - loss: 0.9452 - mean_absolute_error: 0.0258 - categorical_accuracy: 0.7282 - f1_m: 0.6997 - val_loss: 1.6087 - val_mean_absolute_error: 0.0333 - val_categorical_accuracy: 0.5640 - val_f1_m: 0.5351\n",
      "Epoch 42/50\n",
      "4845/4845 [==============================] - 1s 174us/step - loss: 0.9373 - mean_absolute_error: 0.0257 - categorical_accuracy: 0.7329 - f1_m: 0.7039 - val_loss: 1.5988 - val_mean_absolute_error: 0.0328 - val_categorical_accuracy: 0.5751 - val_f1_m: 0.5473\n",
      "Epoch 43/50\n",
      "4845/4845 [==============================] - 1s 173us/step - loss: 0.9264 - mean_absolute_error: 0.0255 - categorical_accuracy: 0.7315 - f1_m: 0.7077 - val_loss: 1.6026 - val_mean_absolute_error: 0.0330 - val_categorical_accuracy: 0.5696 - val_f1_m: 0.5436\n",
      "Epoch 44/50\n",
      "4845/4845 [==============================] - 1s 165us/step - loss: 0.9176 - mean_absolute_error: 0.0254 - categorical_accuracy: 0.7385 - f1_m: 0.7113 - val_loss: 1.6058 - val_mean_absolute_error: 0.0332 - val_categorical_accuracy: 0.5640 - val_f1_m: 0.5369\n",
      "Epoch 45/50\n",
      "4845/4845 [==============================] - 1s 172us/step - loss: 0.9086 - mean_absolute_error: 0.0251 - categorical_accuracy: 0.7389 - f1_m: 0.7167 - val_loss: 1.6012 - val_mean_absolute_error: 0.0328 - val_categorical_accuracy: 0.5751 - val_f1_m: 0.5412\n",
      "Epoch 46/50\n",
      "4845/4845 [==============================] - 1s 168us/step - loss: 0.8972 - mean_absolute_error: 0.0250 - categorical_accuracy: 0.7465 - f1_m: 0.7181 - val_loss: 1.6033 - val_mean_absolute_error: 0.0325 - val_categorical_accuracy: 0.5751 - val_f1_m: 0.5382\n",
      "Epoch 47/50\n",
      "4845/4845 [==============================] - 1s 174us/step - loss: 0.8888 - mean_absolute_error: 0.0248 - categorical_accuracy: 0.7467 - f1_m: 0.7227 - val_loss: 1.6076 - val_mean_absolute_error: 0.0324 - val_categorical_accuracy: 0.5733 - val_f1_m: 0.5471\n",
      "Epoch 48/50\n",
      "4845/4845 [==============================] - 1s 170us/step - loss: 0.8799 - mean_absolute_error: 0.0247 - categorical_accuracy: 0.7517 - f1_m: 0.7247 - val_loss: 1.6052 - val_mean_absolute_error: 0.0324 - val_categorical_accuracy: 0.5788 - val_f1_m: 0.5477\n",
      "Epoch 49/50\n",
      "4845/4845 [==============================] - 1s 173us/step - loss: 0.8724 - mean_absolute_error: 0.0245 - categorical_accuracy: 0.7492 - f1_m: 0.7278 - val_loss: 1.6148 - val_mean_absolute_error: 0.0328 - val_categorical_accuracy: 0.5714 - val_f1_m: 0.5412\n",
      "Epoch 50/50\n",
      "4845/4845 [==============================] - 1s 165us/step - loss: 0.8624 - mean_absolute_error: 0.0243 - categorical_accuracy: 0.7569 - f1_m: 0.7335 - val_loss: 1.6100 - val_mean_absolute_error: 0.0322 - val_categorical_accuracy: 0.5788 - val_f1_m: 0.5521\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from Models import MLP\n",
    "dataset_name = \"meetup\"\n",
    "batch_size = 128\n",
    "num_epochs = 50\n",
    "\n",
    "MLP_model = MLP(input_dimension=hyperedge_embedding_dimension,\n",
    "                 num_outputs=num_categories,\n",
    "                 dataset_name=dataset_name)\n",
    "plot_model(MLP_model, to_file='images/'+dataset_name+'_MLP_model.png')\n",
    "checkpointer = ModelCheckpoint(filepath='weights/'+dataset_name+'/MLP_weights.hdf5', verbose=0, save_best_only=True)\n",
    "tbCallBack = TensorBoard(log_dir='logs/'+dataset_name+'/MLP_logs_multi', histogram_freq=0, batch_size=batch_size, write_graph=True, write_grads=True, write_images=True, update_freq='batch')\n",
    "\n",
    "history = MLP_model.fit(X_MLP_train, Y_MLP_train, epochs=num_epochs, batch_size=batch_size,\n",
    "        shuffle=True, validation_split=0.1,\n",
    "        callbacks=[checkpointer,tbCallBack], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599/599 [==============================] - 1s 1ms/step\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                      Tech       0.53      0.60      0.56        15\n",
      "         Career & Business       0.63      0.61      0.62       105\n",
      "               Socializing       0.00      0.00      0.00         4\n",
      "                     Games       0.59      0.50      0.54        20\n",
      "   Community & Environment       0.00      0.00      0.00         4\n",
      "          Sci-Fi & Fantasy       0.00      0.00      0.00        13\n",
      "        Health & Wellbeing       0.77      0.90      0.83       216\n",
      "                   Singles       0.00      0.00      0.00         6\n",
      "      Education & Learning       0.25      0.25      0.25         4\n",
      "               Photography       0.58      0.70      0.64        10\n",
      "                Book Clubs       0.62      0.62      0.62         8\n",
      "        Religion & Beliefs       0.67      1.00      0.80        12\n",
      "             Movies & Film       0.50      0.25      0.33         8\n",
      "          Hobbies & Crafts       0.46      0.60      0.52        20\n",
      "                      LGBT       1.00      0.33      0.50         3\n",
      "            Pets & Animals       0.39      0.37      0.38        19\n",
      "                   Writing       0.00      0.00      0.00         4\n",
      "    New Age & Spirituality       0.50      0.50      0.50         2\n",
      "                   Dancing       0.14      0.25      0.18         4\n",
      "              Food & Drink       0.57      0.40      0.47        10\n",
      "       Sports & Recreation       0.62      0.50      0.55        16\n",
      "            Arts & Culture       0.31      0.27      0.29        15\n",
      "                     Music       0.00      0.00      0.00         2\n",
      "Language & Ethnic Identity       1.00      0.67      0.80         3\n",
      "      Movements & Politics       0.62      0.83      0.71         6\n",
      "          Fashion & Beauty       0.00      0.00      0.00         5\n",
      "          Parents & Family       1.00      0.20      0.33         5\n",
      "      Outdoors & Adventure       0.50      0.33      0.40         9\n",
      "        Cars & Motorcycles       0.33      0.41      0.37        34\n",
      "                   Fitness       0.60      0.60      0.60        10\n",
      "                   Support       0.00      0.00      0.00         7\n",
      "\n",
      "                 micro avg       0.62      0.62      0.62       599\n",
      "                 macro avg       0.43      0.38      0.38       599\n",
      "              weighted avg       0.59      0.62      0.60       599\n",
      "\n",
      "0.6227045075125208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Y_pred_MLP = MLP_model.predict(X_MLP_test, batch_size=16, verbose=1)\n",
    "finals_pred_MLP = []\n",
    "finals_test_MLP = []\n",
    "for p in Y_pred_MLP:\n",
    "    m = 0\n",
    "    ind = 0\n",
    "    final = 0\n",
    "    for i in p:\n",
    "        if i>m:\n",
    "            m=i\n",
    "            final=ind\n",
    "        ind+=1\n",
    "    finals_pred_MLP.append(final)\n",
    "\n",
    "for i in Y_MLP_test:\n",
    "    ind=0\n",
    "    for j in i:\n",
    "        if j==1:\n",
    "            finals_test_MLP.append(ind)\n",
    "        ind+=1\n",
    "            \n",
    "print(classification_report(finals_test_MLP, finals_pred_MLP, target_names=target_names[:-2]))\n",
    "print(accuracy_score(finals_test_MLP, finals_pred_MLP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingData():\n",
    "    i = 0\n",
    "    lists = []\n",
    "    labels = []\n",
    "    maxi = 0\n",
    "    for h in hyperedges:\n",
    "        vertex_embedding_list = []\n",
    "        hyperedge = hyperedges[h]\n",
    "        for vertex in hyperedge[\"members\"]:\n",
    "            i+=1\n",
    "            if i%100000==0:\n",
    "                print(i)\n",
    "            try: # Good ol' nondeterminism\n",
    "                vertex_embedding_list.append(vertex_embeddings[vertex_ids.index(vertex)].tolist())\n",
    "            except:\n",
    "                print(\"Missed one: \",vertex)\n",
    "        lists.append({\"v\":vertex_embedding_list})\n",
    "        label = np.zeros((num_categories,))\n",
    "        label[int(hyperedge[\"category\"])-1] = 1\n",
    "        labels.append(label)\n",
    "    X_unshuffled = []\n",
    "    \n",
    "    for hlist in lists:\n",
    "        np_vertex_embeddings = np.asarray(hlist[\"v\"])\n",
    "        x = np.zeros((vertex_embedding_dimension*max_groupsize,))\n",
    "        i = 0        \n",
    "        for embedding in np_vertex_embeddings:\n",
    "            x[i*embedding.shape[0]:(i+1)*embedding.shape[0]] = embedding\n",
    "            i+=1\n",
    "        X_unshuffled.append(x)\n",
    "    labels = np.asarray(labels)\n",
    "    X_arr, Y_arr = shuffle(X_unshuffled, labels)\n",
    "    X = np.asarray(X_arr)\n",
    "    Y = np.asarray(Y_arr)\n",
    "    return X, Y\n",
    "\n",
    "X_deepset, Y_deepset = getTrainingData()\n",
    "\n",
    "print(X_deepset.shape)\n",
    "print(Y_deepset.shape)\n",
    "\n",
    "# np.save(datadir+'/X_deepset_'+str(max_groupsize)+'.npy', X_deepset)\n",
    "# np.save(datadir+'/Y_deepset_'+str(max_groupsize)+'.npy', Y_deepset)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_deepset_train, X_deepset_test, Y_deepset_train, Y_deepset_test = train_test_split(X_deepset, Y_deepset, train_size=0.9, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from Models import DeepSets\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "dataset_name = \"meetup\"\n",
    "batch_size = 128\n",
    "num_epochs = 50\n",
    "\n",
    "deepsets_model = DeepSets(vertex_embedding_dimension=vertex_embedding_dimension,\n",
    "                             max_hyperedge_size=max_groupsize,\n",
    "                             num_outputs=num_categories,\n",
    "                             dataset_name=dataset_name)\n",
    "plot_model(deepsets_model, to_file='images/'+dataset_name+'_deepsets_model.png')\n",
    "checkpointer = ModelCheckpoint(filepath='weights/'+dataset_name+'/deepsets_weights.hdf5', verbose=0, save_best_only=True)\n",
    "tbCallBack = TensorBoard(log_dir='logs/'+dataset_name+'/deepsets_logs_multi', histogram_freq=0, batch_size=batch_size, write_graph=True, write_grads=True, write_images=True, update_freq='batch')\n",
    "\n",
    "history = deepsets_model.fit(X_deepset_train, Y_deepset_train, epochs=num_epochs, batch_size=batch_size,\n",
    "        shuffle=True, validation_split=0.1,\n",
    "        callbacks=[checkpointer,tbCallBack], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_deepsets = deepsets_model.predict(X_deepset_test, batch_size=16, verbose=1)\n",
    "target_names = cat_vals\n",
    "finals_pred_deepsets = []\n",
    "finals_test_deepsets = []\n",
    "for p in Y_pred_deepsets:\n",
    "    m = 0\n",
    "    ind = 0\n",
    "    final = 0\n",
    "    for i in p:\n",
    "        if i>m:\n",
    "            m=i\n",
    "            final=ind\n",
    "        ind+=1\n",
    "    finals_pred_deepsets.append(final)\n",
    "\n",
    "for i in Y_deepset_test:\n",
    "    ind=0\n",
    "    for j in i:\n",
    "        if j==1:\n",
    "            finals_test_deepsets.append(ind)\n",
    "        ind+=1\n",
    "            \n",
    "print(classification_report(finals_test_deepsets, finals_pred_deepsets, target_names=target_names))\n",
    "print(accuracy_score(finals_test_deepsets, finals_pred_deepsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
